{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "#from params.py import PROJECT_ID, TABLE_ID\n",
    "import sys; sys.path.append('..')\n",
    "from params import PROJECT_ID, TABLE_ID\n",
    "#from collection import collection\n",
    "#from data_extraction import get_coordinates\n",
    "#from upload_data import send_to_bq\n",
    "\n",
    "#collection() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './raw_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m send_to_bq()\n",
      "File \u001b[0;32m~/code/PauFou/wagon-give-me-a-sign/notebooks/../upload_data.py:15\u001b[0m, in \u001b[0;36msend_to_bq\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m    Envoi de notre échantillon de donnée sur Big Query et suppression de notre échantillon local\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# Envoi de notre échantillon\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m df \u001b[39m=\u001b[39m get_coordinates()\n\u001b[1;32m     17\u001b[0m credentials \u001b[39m=\u001b[39m service_account\u001b[39m.\u001b[39mCredentials\u001b[39m.\u001b[39mfrom_service_account_file(\u001b[39m\"\u001b[39m\u001b[39mbq_keys.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m client \u001b[39m=\u001b[39m bigquery\u001b[39m.\u001b[39mClient(project\u001b[39m=\u001b[39mPROJECT_ID, credentials\u001b[39m=\u001b[39mcredentials)\n",
      "File \u001b[0;32m~/code/PauFou/wagon-give-me-a-sign/notebooks/../data_extraction.py:20\u001b[0m, in \u001b[0;36mget_coordinates\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m DATA_DIR \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./raw_data\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     19\u001b[0m data \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfor\u001b[39;00m dir_ \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(DATA_DIR):\n\u001b[1;32m     21\u001b[0m     \u001b[39mfor\u001b[39;00m img_path \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DATA_DIR, dir_)):\n\u001b[1;32m     23\u001b[0m         img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DATA_DIR, dir_, img_path))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './raw_data'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "send_to_bq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>y_6</th>\n",
       "      <th>z_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>y_7</th>\n",
       "      <th>z_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>y_8</th>\n",
       "      <th>z_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>y_9</th>\n",
       "      <th>z_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>y_10</th>\n",
       "      <th>z_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>y_11</th>\n",
       "      <th>z_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>y_12</th>\n",
       "      <th>z_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>y_13</th>\n",
       "      <th>z_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>y_14</th>\n",
       "      <th>z_14</th>\n",
       "      <th>x_15</th>\n",
       "      <th>y_15</th>\n",
       "      <th>z_15</th>\n",
       "      <th>x_16</th>\n",
       "      <th>y_16</th>\n",
       "      <th>z_16</th>\n",
       "      <th>x_17</th>\n",
       "      <th>y_17</th>\n",
       "      <th>z_17</th>\n",
       "      <th>x_18</th>\n",
       "      <th>y_18</th>\n",
       "      <th>z_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>y_19</th>\n",
       "      <th>z_19</th>\n",
       "      <th>x_20</th>\n",
       "      <th>y_20</th>\n",
       "      <th>z_20</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030617</td>\n",
       "      <td>-0.025593</td>\n",
       "      <td>-0.024471</td>\n",
       "      <td>0.052424</td>\n",
       "      <td>-0.090930</td>\n",
       "      <td>-0.033044</td>\n",
       "      <td>0.055659</td>\n",
       "      <td>-0.157378</td>\n",
       "      <td>-0.038715</td>\n",
       "      <td>0.049222</td>\n",
       "      <td>-0.206274</td>\n",
       "      <td>-0.038759</td>\n",
       "      <td>0.031604</td>\n",
       "      <td>-0.169741</td>\n",
       "      <td>-0.014330</td>\n",
       "      <td>0.026351</td>\n",
       "      <td>-0.221772</td>\n",
       "      <td>-0.037330</td>\n",
       "      <td>0.029117</td>\n",
       "      <td>-0.155124</td>\n",
       "      <td>-0.044791</td>\n",
       "      <td>0.030951</td>\n",
       "      <td>-0.138266</td>\n",
       "      <td>-0.045978</td>\n",
       "      <td>0.007571</td>\n",
       "      <td>-0.163045</td>\n",
       "      <td>-0.009283</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>-0.205632</td>\n",
       "      <td>-0.033765</td>\n",
       "      <td>0.012425</td>\n",
       "      <td>-0.129860</td>\n",
       "      <td>-0.034348</td>\n",
       "      <td>0.014008</td>\n",
       "      <td>-0.128321</td>\n",
       "      <td>-0.028510</td>\n",
       "      <td>-0.015352</td>\n",
       "      <td>-0.153569</td>\n",
       "      <td>-0.008907</td>\n",
       "      <td>-0.019343</td>\n",
       "      <td>-0.184335</td>\n",
       "      <td>-0.034417</td>\n",
       "      <td>-0.009376</td>\n",
       "      <td>-0.115278</td>\n",
       "      <td>-0.024837</td>\n",
       "      <td>-0.006334</td>\n",
       "      <td>-0.114446</td>\n",
       "      <td>-0.011570</td>\n",
       "      <td>-0.039170</td>\n",
       "      <td>-0.143449</td>\n",
       "      <td>-0.010533</td>\n",
       "      <td>-0.041114</td>\n",
       "      <td>-0.168253</td>\n",
       "      <td>-0.023340</td>\n",
       "      <td>-0.031356</td>\n",
       "      <td>-0.120621</td>\n",
       "      <td>-0.014337</td>\n",
       "      <td>-0.027999</td>\n",
       "      <td>-0.109138</td>\n",
       "      <td>-0.003662</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039712</td>\n",
       "      <td>-0.009938</td>\n",
       "      <td>-0.014068</td>\n",
       "      <td>0.082862</td>\n",
       "      <td>-0.073176</td>\n",
       "      <td>-0.016867</td>\n",
       "      <td>0.100336</td>\n",
       "      <td>-0.132777</td>\n",
       "      <td>-0.017930</td>\n",
       "      <td>0.109060</td>\n",
       "      <td>-0.181419</td>\n",
       "      <td>-0.014515</td>\n",
       "      <td>0.061054</td>\n",
       "      <td>-0.181493</td>\n",
       "      <td>-0.010170</td>\n",
       "      <td>0.088003</td>\n",
       "      <td>-0.192976</td>\n",
       "      <td>-0.025545</td>\n",
       "      <td>0.074451</td>\n",
       "      <td>-0.127280</td>\n",
       "      <td>-0.029147</td>\n",
       "      <td>0.062553</td>\n",
       "      <td>-0.127172</td>\n",
       "      <td>-0.030470</td>\n",
       "      <td>0.033998</td>\n",
       "      <td>-0.191481</td>\n",
       "      <td>-0.010995</td>\n",
       "      <td>0.063322</td>\n",
       "      <td>-0.196085</td>\n",
       "      <td>-0.029340</td>\n",
       "      <td>0.051812</td>\n",
       "      <td>-0.116627</td>\n",
       "      <td>-0.031295</td>\n",
       "      <td>0.039058</td>\n",
       "      <td>-0.124022</td>\n",
       "      <td>-0.029795</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>-0.188438</td>\n",
       "      <td>-0.014084</td>\n",
       "      <td>0.035253</td>\n",
       "      <td>-0.198305</td>\n",
       "      <td>-0.036287</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>-0.118876</td>\n",
       "      <td>-0.028423</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>-0.121275</td>\n",
       "      <td>-0.019194</td>\n",
       "      <td>-0.019736</td>\n",
       "      <td>-0.178523</td>\n",
       "      <td>-0.017697</td>\n",
       "      <td>0.009595</td>\n",
       "      <td>-0.182768</td>\n",
       "      <td>-0.032774</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>-0.129140</td>\n",
       "      <td>-0.025251</td>\n",
       "      <td>-0.005569</td>\n",
       "      <td>-0.126195</td>\n",
       "      <td>-0.016695</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028283</td>\n",
       "      <td>-0.027583</td>\n",
       "      <td>-0.028074</td>\n",
       "      <td>0.049251</td>\n",
       "      <td>-0.094604</td>\n",
       "      <td>-0.038543</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>-0.163788</td>\n",
       "      <td>-0.045716</td>\n",
       "      <td>0.044315</td>\n",
       "      <td>-0.215442</td>\n",
       "      <td>-0.047283</td>\n",
       "      <td>0.029086</td>\n",
       "      <td>-0.181012</td>\n",
       "      <td>-0.012654</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>-0.223811</td>\n",
       "      <td>-0.035704</td>\n",
       "      <td>0.024830</td>\n",
       "      <td>-0.161946</td>\n",
       "      <td>-0.044303</td>\n",
       "      <td>0.028244</td>\n",
       "      <td>-0.146778</td>\n",
       "      <td>-0.046157</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>-0.175239</td>\n",
       "      <td>-0.005750</td>\n",
       "      <td>-0.001370</td>\n",
       "      <td>-0.210049</td>\n",
       "      <td>-0.029545</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>-0.137339</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>0.011906</td>\n",
       "      <td>-0.138638</td>\n",
       "      <td>-0.024177</td>\n",
       "      <td>-0.018055</td>\n",
       "      <td>-0.164318</td>\n",
       "      <td>-0.004162</td>\n",
       "      <td>-0.024217</td>\n",
       "      <td>-0.187287</td>\n",
       "      <td>-0.029596</td>\n",
       "      <td>-0.013244</td>\n",
       "      <td>-0.123151</td>\n",
       "      <td>-0.020404</td>\n",
       "      <td>-0.008607</td>\n",
       "      <td>-0.124421</td>\n",
       "      <td>-0.007234</td>\n",
       "      <td>-0.041484</td>\n",
       "      <td>-0.151860</td>\n",
       "      <td>-0.004945</td>\n",
       "      <td>-0.044676</td>\n",
       "      <td>-0.173983</td>\n",
       "      <td>-0.018228</td>\n",
       "      <td>-0.035034</td>\n",
       "      <td>-0.128237</td>\n",
       "      <td>-0.009689</td>\n",
       "      <td>-0.030772</td>\n",
       "      <td>-0.117302</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042064</td>\n",
       "      <td>-0.036703</td>\n",
       "      <td>-0.009524</td>\n",
       "      <td>0.069313</td>\n",
       "      <td>-0.113975</td>\n",
       "      <td>-0.010303</td>\n",
       "      <td>0.081982</td>\n",
       "      <td>-0.184698</td>\n",
       "      <td>-0.012622</td>\n",
       "      <td>0.077904</td>\n",
       "      <td>-0.236617</td>\n",
       "      <td>-0.010728</td>\n",
       "      <td>0.043873</td>\n",
       "      <td>-0.190953</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>0.064259</td>\n",
       "      <td>-0.235749</td>\n",
       "      <td>-0.010846</td>\n",
       "      <td>0.060653</td>\n",
       "      <td>-0.165986</td>\n",
       "      <td>-0.013245</td>\n",
       "      <td>0.048666</td>\n",
       "      <td>-0.155903</td>\n",
       "      <td>-0.012194</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>-0.196641</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.042590</td>\n",
       "      <td>-0.230071</td>\n",
       "      <td>-0.016266</td>\n",
       "      <td>0.040733</td>\n",
       "      <td>-0.147912</td>\n",
       "      <td>-0.015825</td>\n",
       "      <td>0.027252</td>\n",
       "      <td>-0.150937</td>\n",
       "      <td>-0.011389</td>\n",
       "      <td>-0.000695</td>\n",
       "      <td>-0.194614</td>\n",
       "      <td>-0.005253</td>\n",
       "      <td>0.018757</td>\n",
       "      <td>-0.236576</td>\n",
       "      <td>-0.027264</td>\n",
       "      <td>0.018586</td>\n",
       "      <td>-0.155801</td>\n",
       "      <td>-0.017471</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>-0.147006</td>\n",
       "      <td>-0.005684</td>\n",
       "      <td>-0.026854</td>\n",
       "      <td>-0.187424</td>\n",
       "      <td>-0.012568</td>\n",
       "      <td>-0.006809</td>\n",
       "      <td>-0.232942</td>\n",
       "      <td>-0.025460</td>\n",
       "      <td>-0.002062</td>\n",
       "      <td>-0.178175</td>\n",
       "      <td>-0.015476</td>\n",
       "      <td>-0.012370</td>\n",
       "      <td>-0.157360</td>\n",
       "      <td>-0.004711</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035891</td>\n",
       "      <td>-0.020031</td>\n",
       "      <td>-0.017844</td>\n",
       "      <td>0.067554</td>\n",
       "      <td>-0.075301</td>\n",
       "      <td>-0.023967</td>\n",
       "      <td>0.081924</td>\n",
       "      <td>-0.129552</td>\n",
       "      <td>-0.027796</td>\n",
       "      <td>0.090698</td>\n",
       "      <td>-0.173344</td>\n",
       "      <td>-0.026866</td>\n",
       "      <td>0.047956</td>\n",
       "      <td>-0.156993</td>\n",
       "      <td>-0.014713</td>\n",
       "      <td>0.067162</td>\n",
       "      <td>-0.183935</td>\n",
       "      <td>-0.030874</td>\n",
       "      <td>0.059137</td>\n",
       "      <td>-0.123290</td>\n",
       "      <td>-0.033990</td>\n",
       "      <td>0.048083</td>\n",
       "      <td>-0.118256</td>\n",
       "      <td>-0.034389</td>\n",
       "      <td>0.021812</td>\n",
       "      <td>-0.163919</td>\n",
       "      <td>-0.013156</td>\n",
       "      <td>0.041043</td>\n",
       "      <td>-0.184841</td>\n",
       "      <td>-0.031590</td>\n",
       "      <td>0.036477</td>\n",
       "      <td>-0.111153</td>\n",
       "      <td>-0.032316</td>\n",
       "      <td>0.028582</td>\n",
       "      <td>-0.116213</td>\n",
       "      <td>-0.029897</td>\n",
       "      <td>-0.002225</td>\n",
       "      <td>-0.157490</td>\n",
       "      <td>-0.014223</td>\n",
       "      <td>0.014336</td>\n",
       "      <td>-0.172692</td>\n",
       "      <td>-0.034557</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>-0.105591</td>\n",
       "      <td>-0.026624</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>-0.110778</td>\n",
       "      <td>-0.017790</td>\n",
       "      <td>-0.025569</td>\n",
       "      <td>-0.146199</td>\n",
       "      <td>-0.016402</td>\n",
       "      <td>-0.009016</td>\n",
       "      <td>-0.155044</td>\n",
       "      <td>-0.029003</td>\n",
       "      <td>-0.005165</td>\n",
       "      <td>-0.111559</td>\n",
       "      <td>-0.022085</td>\n",
       "      <td>-0.013341</td>\n",
       "      <td>-0.109609</td>\n",
       "      <td>-0.014636</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027759</td>\n",
       "      <td>-0.009717</td>\n",
       "      <td>-0.007931</td>\n",
       "      <td>0.048734</td>\n",
       "      <td>-0.055194</td>\n",
       "      <td>-0.011336</td>\n",
       "      <td>0.059750</td>\n",
       "      <td>-0.093314</td>\n",
       "      <td>-0.014967</td>\n",
       "      <td>0.047682</td>\n",
       "      <td>-0.111453</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>0.036554</td>\n",
       "      <td>-0.141412</td>\n",
       "      <td>-0.007818</td>\n",
       "      <td>0.041717</td>\n",
       "      <td>-0.199753</td>\n",
       "      <td>-0.016856</td>\n",
       "      <td>0.044491</td>\n",
       "      <td>-0.237249</td>\n",
       "      <td>-0.025295</td>\n",
       "      <td>0.046795</td>\n",
       "      <td>-0.270831</td>\n",
       "      <td>-0.032012</td>\n",
       "      <td>0.022770</td>\n",
       "      <td>-0.145322</td>\n",
       "      <td>-0.012156</td>\n",
       "      <td>0.026829</td>\n",
       "      <td>-0.210616</td>\n",
       "      <td>-0.020809</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>-0.255648</td>\n",
       "      <td>-0.029657</td>\n",
       "      <td>0.036184</td>\n",
       "      <td>-0.295196</td>\n",
       "      <td>-0.036339</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>-0.135603</td>\n",
       "      <td>-0.017685</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>-0.198573</td>\n",
       "      <td>-0.026775</td>\n",
       "      <td>0.014551</td>\n",
       "      <td>-0.239687</td>\n",
       "      <td>-0.033980</td>\n",
       "      <td>0.018831</td>\n",
       "      <td>-0.275919</td>\n",
       "      <td>-0.038897</td>\n",
       "      <td>-0.007873</td>\n",
       "      <td>-0.115283</td>\n",
       "      <td>-0.024134</td>\n",
       "      <td>-0.005130</td>\n",
       "      <td>-0.164678</td>\n",
       "      <td>-0.033563</td>\n",
       "      <td>-0.000998</td>\n",
       "      <td>-0.198500</td>\n",
       "      <td>-0.038672</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>-0.230358</td>\n",
       "      <td>-0.042076</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036238</td>\n",
       "      <td>-0.014242</td>\n",
       "      <td>-0.014623</td>\n",
       "      <td>0.063670</td>\n",
       "      <td>-0.069462</td>\n",
       "      <td>-0.022983</td>\n",
       "      <td>0.075624</td>\n",
       "      <td>-0.122716</td>\n",
       "      <td>-0.030998</td>\n",
       "      <td>0.057918</td>\n",
       "      <td>-0.144311</td>\n",
       "      <td>-0.040446</td>\n",
       "      <td>0.045622</td>\n",
       "      <td>-0.184200</td>\n",
       "      <td>-0.019768</td>\n",
       "      <td>0.050257</td>\n",
       "      <td>-0.264872</td>\n",
       "      <td>-0.034608</td>\n",
       "      <td>0.052240</td>\n",
       "      <td>-0.317630</td>\n",
       "      <td>-0.047027</td>\n",
       "      <td>0.053478</td>\n",
       "      <td>-0.364399</td>\n",
       "      <td>-0.056825</td>\n",
       "      <td>0.023161</td>\n",
       "      <td>-0.190842</td>\n",
       "      <td>-0.024943</td>\n",
       "      <td>0.027840</td>\n",
       "      <td>-0.283768</td>\n",
       "      <td>-0.039961</td>\n",
       "      <td>0.032079</td>\n",
       "      <td>-0.345407</td>\n",
       "      <td>-0.053273</td>\n",
       "      <td>0.036118</td>\n",
       "      <td>-0.398530</td>\n",
       "      <td>-0.063080</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>-0.179679</td>\n",
       "      <td>-0.031577</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>-0.269629</td>\n",
       "      <td>-0.046901</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>-0.328219</td>\n",
       "      <td>-0.058685</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>-0.378100</td>\n",
       "      <td>-0.066403</td>\n",
       "      <td>-0.021953</td>\n",
       "      <td>-0.154743</td>\n",
       "      <td>-0.039490</td>\n",
       "      <td>-0.020787</td>\n",
       "      <td>-0.225819</td>\n",
       "      <td>-0.054815</td>\n",
       "      <td>-0.017541</td>\n",
       "      <td>-0.274082</td>\n",
       "      <td>-0.063863</td>\n",
       "      <td>-0.012862</td>\n",
       "      <td>-0.318733</td>\n",
       "      <td>-0.069807</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034023</td>\n",
       "      <td>-0.013322</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>0.055381</td>\n",
       "      <td>-0.060999</td>\n",
       "      <td>-0.003476</td>\n",
       "      <td>0.064390</td>\n",
       "      <td>-0.098859</td>\n",
       "      <td>-0.004921</td>\n",
       "      <td>0.060494</td>\n",
       "      <td>-0.123811</td>\n",
       "      <td>-0.007554</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>-0.135982</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.048183</td>\n",
       "      <td>-0.192760</td>\n",
       "      <td>-0.006876</td>\n",
       "      <td>0.054349</td>\n",
       "      <td>-0.231413</td>\n",
       "      <td>-0.013861</td>\n",
       "      <td>0.059498</td>\n",
       "      <td>-0.265151</td>\n",
       "      <td>-0.019514</td>\n",
       "      <td>0.029449</td>\n",
       "      <td>-0.139622</td>\n",
       "      <td>-0.005162</td>\n",
       "      <td>0.036992</td>\n",
       "      <td>-0.201951</td>\n",
       "      <td>-0.013065</td>\n",
       "      <td>0.045386</td>\n",
       "      <td>-0.245858</td>\n",
       "      <td>-0.022018</td>\n",
       "      <td>0.053187</td>\n",
       "      <td>-0.285802</td>\n",
       "      <td>-0.028547</td>\n",
       "      <td>0.017189</td>\n",
       "      <td>-0.131897</td>\n",
       "      <td>-0.011645</td>\n",
       "      <td>0.024220</td>\n",
       "      <td>-0.195873</td>\n",
       "      <td>-0.021081</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>-0.238762</td>\n",
       "      <td>-0.028835</td>\n",
       "      <td>0.038817</td>\n",
       "      <td>-0.276861</td>\n",
       "      <td>-0.033724</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>-0.114666</td>\n",
       "      <td>-0.018467</td>\n",
       "      <td>0.007599</td>\n",
       "      <td>-0.167055</td>\n",
       "      <td>-0.027502</td>\n",
       "      <td>0.013094</td>\n",
       "      <td>-0.200872</td>\n",
       "      <td>-0.032159</td>\n",
       "      <td>0.019281</td>\n",
       "      <td>-0.233391</td>\n",
       "      <td>-0.035239</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035882</td>\n",
       "      <td>-0.017819</td>\n",
       "      <td>-0.015443</td>\n",
       "      <td>0.064901</td>\n",
       "      <td>-0.073411</td>\n",
       "      <td>-0.023921</td>\n",
       "      <td>0.077064</td>\n",
       "      <td>-0.129204</td>\n",
       "      <td>-0.032050</td>\n",
       "      <td>0.056060</td>\n",
       "      <td>-0.155068</td>\n",
       "      <td>-0.041392</td>\n",
       "      <td>0.045544</td>\n",
       "      <td>-0.188729</td>\n",
       "      <td>-0.019623</td>\n",
       "      <td>0.048693</td>\n",
       "      <td>-0.270878</td>\n",
       "      <td>-0.034281</td>\n",
       "      <td>0.050146</td>\n",
       "      <td>-0.323200</td>\n",
       "      <td>-0.046469</td>\n",
       "      <td>0.051187</td>\n",
       "      <td>-0.370209</td>\n",
       "      <td>-0.056103</td>\n",
       "      <td>0.023086</td>\n",
       "      <td>-0.195077</td>\n",
       "      <td>-0.024390</td>\n",
       "      <td>0.025921</td>\n",
       "      <td>-0.290244</td>\n",
       "      <td>-0.039100</td>\n",
       "      <td>0.029478</td>\n",
       "      <td>-0.351660</td>\n",
       "      <td>-0.051781</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>-0.405007</td>\n",
       "      <td>-0.061163</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>-0.183655</td>\n",
       "      <td>-0.030760</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>-0.274379</td>\n",
       "      <td>-0.045550</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>-0.332992</td>\n",
       "      <td>-0.056581</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>-0.383111</td>\n",
       "      <td>-0.063850</td>\n",
       "      <td>-0.021886</td>\n",
       "      <td>-0.158571</td>\n",
       "      <td>-0.038613</td>\n",
       "      <td>-0.021022</td>\n",
       "      <td>-0.229598</td>\n",
       "      <td>-0.053284</td>\n",
       "      <td>-0.018071</td>\n",
       "      <td>-0.278272</td>\n",
       "      <td>-0.061909</td>\n",
       "      <td>-0.014056</td>\n",
       "      <td>-0.323385</td>\n",
       "      <td>-0.067643</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027822</td>\n",
       "      <td>-0.008035</td>\n",
       "      <td>-0.008212</td>\n",
       "      <td>0.046850</td>\n",
       "      <td>-0.046811</td>\n",
       "      <td>-0.012060</td>\n",
       "      <td>0.057594</td>\n",
       "      <td>-0.075770</td>\n",
       "      <td>-0.016012</td>\n",
       "      <td>0.055293</td>\n",
       "      <td>-0.094701</td>\n",
       "      <td>-0.020944</td>\n",
       "      <td>0.037018</td>\n",
       "      <td>-0.130690</td>\n",
       "      <td>-0.009938</td>\n",
       "      <td>0.041207</td>\n",
       "      <td>-0.186585</td>\n",
       "      <td>-0.020116</td>\n",
       "      <td>0.044098</td>\n",
       "      <td>-0.223345</td>\n",
       "      <td>-0.029045</td>\n",
       "      <td>0.046472</td>\n",
       "      <td>-0.256053</td>\n",
       "      <td>-0.035915</td>\n",
       "      <td>0.023518</td>\n",
       "      <td>-0.135898</td>\n",
       "      <td>-0.014124</td>\n",
       "      <td>0.026047</td>\n",
       "      <td>-0.200808</td>\n",
       "      <td>-0.024960</td>\n",
       "      <td>0.029428</td>\n",
       "      <td>-0.246264</td>\n",
       "      <td>-0.035381</td>\n",
       "      <td>0.033228</td>\n",
       "      <td>-0.284051</td>\n",
       "      <td>-0.042776</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>-0.127331</td>\n",
       "      <td>-0.019290</td>\n",
       "      <td>0.009955</td>\n",
       "      <td>-0.191311</td>\n",
       "      <td>-0.030605</td>\n",
       "      <td>0.012028</td>\n",
       "      <td>-0.233684</td>\n",
       "      <td>-0.039552</td>\n",
       "      <td>0.015260</td>\n",
       "      <td>-0.269696</td>\n",
       "      <td>-0.045107</td>\n",
       "      <td>-0.007216</td>\n",
       "      <td>-0.107548</td>\n",
       "      <td>-0.025120</td>\n",
       "      <td>-0.006422</td>\n",
       "      <td>-0.158425</td>\n",
       "      <td>-0.036977</td>\n",
       "      <td>-0.004116</td>\n",
       "      <td>-0.193321</td>\n",
       "      <td>-0.043764</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>-0.225975</td>\n",
       "      <td>-0.047803</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_0  y_0  z_0       x_1  ...      x_20      y_20      z_20  target\n",
       "0     0.0  0.0  0.0  0.030617  ... -0.027999 -0.109138 -0.003662       a\n",
       "1     0.0  0.0  0.0  0.039712  ... -0.005569 -0.126195 -0.016695       a\n",
       "2     0.0  0.0  0.0  0.028283  ... -0.030772 -0.117302  0.001057       a\n",
       "3     0.0  0.0  0.0  0.042064  ... -0.012370 -0.157360 -0.004711       a\n",
       "4     0.0  0.0  0.0  0.035891  ... -0.013341 -0.109609 -0.014636       a\n",
       "...   ...  ...  ...       ...  ...       ...       ...       ...     ...\n",
       "1485  0.0  0.0  0.0  0.027759  ...  0.004311 -0.230358 -0.042076       b\n",
       "1486  0.0  0.0  0.0  0.036238  ... -0.012862 -0.318733 -0.069807       b\n",
       "1487  0.0  0.0  0.0  0.034023  ...  0.019281 -0.233391 -0.035239       b\n",
       "1488  0.0  0.0  0.0  0.035882  ... -0.014056 -0.323385 -0.067643       b\n",
       "1489  0.0  0.0  0.0  0.027822  ...  0.000212 -0.225975 -0.047803       b\n",
       "\n",
       "[1490 rows x 64 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\"../bq_keys.json\")\n",
    "client = bigquery.Client(project=PROJECT_ID, credentials=credentials)\n",
    "table = client.get_table(\"test_dataset.test30\")\n",
    "\n",
    "\n",
    "# Construct the SQL query to retrieve the table data\n",
    "query = f'SELECT * FROM `{table}`'\n",
    "\n",
    "# Submit the query and fetch the results\n",
    "df = client.query(query).to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# séparation des données\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "# encoder les étiquettes de classe\n",
    "encoder= LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# diviser les données en ensembles de formation et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.6149 - accuracy: 0.3993 - val_loss: 1.2898 - val_accuracy: 0.4721\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.9727 - accuracy: 0.6703 - val_loss: 0.7119 - val_accuracy: 0.7598\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.8633 - val_loss: 0.4071 - val_accuracy: 0.9413\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.9149 - val_loss: 0.2945 - val_accuracy: 0.9553\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.9365 - val_loss: 0.2502 - val_accuracy: 0.9469\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2403 - accuracy: 0.9496 - val_loss: 0.1975 - val_accuracy: 0.9665\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9508 - val_loss: 0.1829 - val_accuracy: 0.9721\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9616 - val_loss: 0.1647 - val_accuracy: 0.9721\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.9616 - val_loss: 0.1696 - val_accuracy: 0.9721\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.9616 - val_loss: 0.1434 - val_accuracy: 0.9721\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1698 - accuracy: 0.9616 - val_loss: 0.1336 - val_accuracy: 0.9749\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9736 - val_loss: 0.1332 - val_accuracy: 0.9721\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9700 - val_loss: 0.1375 - val_accuracy: 0.9721\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9712 - val_loss: 0.1441 - val_accuracy: 0.9721\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9772 - val_loss: 0.1422 - val_accuracy: 0.9721\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9796 - val_loss: 0.1427 - val_accuracy: 0.9749\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9724 - val_loss: 0.1538 - val_accuracy: 0.9721\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9772 - val_loss: 0.1454 - val_accuracy: 0.9721\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.9784 - val_loss: 0.1544 - val_accuracy: 0.9721\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9808 - val_loss: 0.1578 - val_accuracy: 0.9721\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9784 - val_loss: 0.1621 - val_accuracy: 0.9721\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9784 - val_loss: 0.1566 - val_accuracy: 0.9721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x287ac8df0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# petit earlystopping des familles\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "# définir le modèle\n",
    "model = Sequential(probability=True)\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(len(set(y)), activation='softmax')) \n",
    "\n",
    "# compiler le modèle\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# former le modèle\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=16, validation_split=0.30, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11708107590675354, 0.9664429426193237]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.predict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test avec autres mains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>...</th>\n",
       "      <th>x_18</th>\n",
       "      <th>y_18</th>\n",
       "      <th>z_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>y_19</th>\n",
       "      <th>z_19</th>\n",
       "      <th>x_20</th>\n",
       "      <th>y_20</th>\n",
       "      <th>z_20</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068996</td>\n",
       "      <td>-0.001794</td>\n",
       "      <td>-0.026495</td>\n",
       "      <td>0.129794</td>\n",
       "      <td>-0.049328</td>\n",
       "      <td>-0.037758</td>\n",
       "      <td>0.157946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>-0.236859</td>\n",
       "      <td>-0.053696</td>\n",
       "      <td>0.014897</td>\n",
       "      <td>-0.160986</td>\n",
       "      <td>-0.042879</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>-0.143430</td>\n",
       "      <td>-0.028293</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>-0.004527</td>\n",
       "      <td>-0.035077</td>\n",
       "      <td>0.159894</td>\n",
       "      <td>-0.063521</td>\n",
       "      <td>-0.049802</td>\n",
       "      <td>0.195749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022846</td>\n",
       "      <td>-0.301951</td>\n",
       "      <td>-0.067628</td>\n",
       "      <td>0.019003</td>\n",
       "      <td>-0.205834</td>\n",
       "      <td>-0.053242</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>-0.182658</td>\n",
       "      <td>-0.034498</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>-0.039060</td>\n",
       "      <td>0.166663</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-0.056427</td>\n",
       "      <td>0.204637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011525</td>\n",
       "      <td>-0.315707</td>\n",
       "      <td>-0.082841</td>\n",
       "      <td>0.011519</td>\n",
       "      <td>-0.209255</td>\n",
       "      <td>-0.069801</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.184926</td>\n",
       "      <td>-0.051607</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072380</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>-0.018210</td>\n",
       "      <td>0.133630</td>\n",
       "      <td>-0.037806</td>\n",
       "      <td>-0.024918</td>\n",
       "      <td>0.162663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032818</td>\n",
       "      <td>-0.254179</td>\n",
       "      <td>-0.044583</td>\n",
       "      <td>0.030884</td>\n",
       "      <td>-0.179450</td>\n",
       "      <td>-0.034737</td>\n",
       "      <td>0.014321</td>\n",
       "      <td>-0.144736</td>\n",
       "      <td>-0.021350</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087307</td>\n",
       "      <td>-0.013774</td>\n",
       "      <td>-0.015136</td>\n",
       "      <td>0.145934</td>\n",
       "      <td>-0.070759</td>\n",
       "      <td>-0.021705</td>\n",
       "      <td>0.181889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044853</td>\n",
       "      <td>-0.331586</td>\n",
       "      <td>-0.057311</td>\n",
       "      <td>0.039559</td>\n",
       "      <td>-0.234893</td>\n",
       "      <td>-0.044078</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>-0.194194</td>\n",
       "      <td>-0.025516</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>-0.030207</td>\n",
       "      <td>-0.015475</td>\n",
       "      <td>0.099631</td>\n",
       "      <td>-0.108319</td>\n",
       "      <td>-0.016353</td>\n",
       "      <td>0.097771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015726</td>\n",
       "      <td>-0.307548</td>\n",
       "      <td>-0.022291</td>\n",
       "      <td>0.024386</td>\n",
       "      <td>-0.356151</td>\n",
       "      <td>-0.029392</td>\n",
       "      <td>0.031174</td>\n",
       "      <td>-0.400676</td>\n",
       "      <td>-0.034954</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060126</td>\n",
       "      <td>-0.017372</td>\n",
       "      <td>-0.013335</td>\n",
       "      <td>0.105420</td>\n",
       "      <td>-0.098992</td>\n",
       "      <td>-0.012475</td>\n",
       "      <td>0.108897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029067</td>\n",
       "      <td>-0.332348</td>\n",
       "      <td>-0.025400</td>\n",
       "      <td>0.040817</td>\n",
       "      <td>-0.387573</td>\n",
       "      <td>-0.033769</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>-0.437535</td>\n",
       "      <td>-0.039949</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070404</td>\n",
       "      <td>-0.006071</td>\n",
       "      <td>-0.017204</td>\n",
       "      <td>0.135407</td>\n",
       "      <td>-0.109200</td>\n",
       "      <td>-0.017203</td>\n",
       "      <td>0.149792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051218</td>\n",
       "      <td>-0.426427</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>0.069479</td>\n",
       "      <td>-0.499157</td>\n",
       "      <td>-0.057802</td>\n",
       "      <td>0.083838</td>\n",
       "      <td>-0.569521</td>\n",
       "      <td>-0.065745</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068547</td>\n",
       "      <td>-0.012165</td>\n",
       "      <td>-0.014034</td>\n",
       "      <td>0.125481</td>\n",
       "      <td>-0.104795</td>\n",
       "      <td>-0.012689</td>\n",
       "      <td>0.135076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>-0.398056</td>\n",
       "      <td>-0.035419</td>\n",
       "      <td>0.063773</td>\n",
       "      <td>-0.464220</td>\n",
       "      <td>-0.046029</td>\n",
       "      <td>0.074907</td>\n",
       "      <td>-0.525973</td>\n",
       "      <td>-0.053582</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064126</td>\n",
       "      <td>-0.020897</td>\n",
       "      <td>-0.023634</td>\n",
       "      <td>0.111174</td>\n",
       "      <td>-0.106944</td>\n",
       "      <td>-0.024843</td>\n",
       "      <td>0.109917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018873</td>\n",
       "      <td>-0.320796</td>\n",
       "      <td>-0.013422</td>\n",
       "      <td>0.030369</td>\n",
       "      <td>-0.371408</td>\n",
       "      <td>-0.024301</td>\n",
       "      <td>0.039568</td>\n",
       "      <td>-0.417912</td>\n",
       "      <td>-0.033064</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_0  y_0  z_0       x_1       y_1       z_1       x_2       y_2  \\\n",
       "0    0.0  0.0  0.0  0.068996 -0.001794 -0.026495  0.129794 -0.049328   \n",
       "1    0.0  0.0  0.0  0.084189 -0.004527 -0.035077  0.159894 -0.063521   \n",
       "2    0.0  0.0  0.0  0.081866  0.003673 -0.039060  0.166663 -0.060628   \n",
       "3    0.0  0.0  0.0  0.072380  0.001230 -0.018210  0.133630 -0.037806   \n",
       "4    0.0  0.0  0.0  0.087307 -0.013774 -0.015136  0.145934 -0.070759   \n",
       "..   ...  ...  ...       ...       ...       ...       ...       ...   \n",
       "625  0.0  0.0  0.0  0.058419 -0.030207 -0.015475  0.099631 -0.108319   \n",
       "626  0.0  0.0  0.0  0.060126 -0.017372 -0.013335  0.105420 -0.098992   \n",
       "627  0.0  0.0  0.0  0.070404 -0.006071 -0.017204  0.135407 -0.109200   \n",
       "628  0.0  0.0  0.0  0.068547 -0.012165 -0.014034  0.125481 -0.104795   \n",
       "629  0.0  0.0  0.0  0.064126 -0.020897 -0.023634  0.111174 -0.106944   \n",
       "\n",
       "          z_2       x_3  ...      x_18      y_18      z_18      x_19  \\\n",
       "0   -0.037758  0.157946  ...  0.015763 -0.236859 -0.053696  0.014897   \n",
       "1   -0.049802  0.195749  ...  0.022846 -0.301951 -0.067628  0.019003   \n",
       "2   -0.056427  0.204637  ...  0.011525 -0.315707 -0.082841  0.011519   \n",
       "3   -0.024918  0.162663  ...  0.032818 -0.254179 -0.044583  0.030884   \n",
       "4   -0.021705  0.181889  ...  0.044853 -0.331586 -0.057311  0.039559   \n",
       "..        ...       ...  ...       ...       ...       ...       ...   \n",
       "625 -0.016353  0.097771  ...  0.015726 -0.307548 -0.022291  0.024386   \n",
       "626 -0.012475  0.108897  ...  0.029067 -0.332348 -0.025400  0.040817   \n",
       "627 -0.017203  0.149792  ...  0.051218 -0.426427 -0.046215  0.069479   \n",
       "628 -0.012689  0.135076  ...  0.048240 -0.398056 -0.035419  0.063773   \n",
       "629 -0.024843  0.109917  ...  0.018873 -0.320796 -0.013422  0.030369   \n",
       "\n",
       "         y_19      z_19      x_20      y_20      z_20  target  \n",
       "0   -0.160986 -0.042879  0.003309 -0.143430 -0.028293       a  \n",
       "1   -0.205834 -0.053242  0.004331 -0.182658 -0.034498       a  \n",
       "2   -0.209255 -0.069801 -0.000003 -0.184926 -0.051607       a  \n",
       "3   -0.179450 -0.034737  0.014321 -0.144736 -0.021350       a  \n",
       "4   -0.234893 -0.044078  0.012328 -0.194194 -0.025516       a  \n",
       "..        ...       ...       ...       ...       ...     ...  \n",
       "625 -0.356151 -0.029392  0.031174 -0.400676 -0.034954       b  \n",
       "626 -0.387573 -0.033769  0.049316 -0.437535 -0.039949       b  \n",
       "627 -0.499157 -0.057802  0.083838 -0.569521 -0.065745       b  \n",
       "628 -0.464220 -0.046029  0.074907 -0.525973 -0.053582       b  \n",
       "629 -0.371408 -0.024301  0.039568 -0.417912 -0.033064       b  \n",
       "\n",
       "[630 rows x 64 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(\"../bq_keys.json\")\n",
    "client = bigquery.Client(project=PROJECT_ID, credentials=credentials)\n",
    "table = client.get_table(\"test_dataset.test10\")\n",
    "\n",
    "\n",
    "# Construct the SQL query to retrieve the table data\n",
    "query = f'SELECT * FROM `{table}`'\n",
    "\n",
    "# Submit the query and fetch the results\n",
    "df_test = client.query(query).to_dataframe()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 16:31:14.821109: W tensorflow/core/framework/op_kernel.cc:1805] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"/Users/paul/.pyenv/versions/3.10.6/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/paul/.pyenv/versions/3.10.6/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/paul/.pyenv/versions/3.10.6/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/Users/paul/.pyenv/versions/3.10.6/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/Users/paul/.pyenv/versions/3.10.6/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/7z/89c1vd1s6xlcjd9373__jcr40000gn/T/ipykernel_23857/1708662303.py\", line 5, in <module>\n      model.evaluate(X_autre, y_autre)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2200, in evaluate\n      logs = test_function_runner.run_step(\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 4000, in run_step\n      tmp_logs = self._function(dataset_or_iterator)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1972, in test_function\n      return step_function(self, iterator)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1956, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1944, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1853, in test_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1179, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 708, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_test_function_20002]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m X_autre \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m y_autre \u001b[39m=\u001b[39m df_test[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m model\u001b[39m.\u001b[39;49mevaluate(X_autre, y_autre)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"/Users/paul/.pyenv/versions/3.10.6/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/paul/.pyenv/versions/3.10.6/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/paul/.pyenv/versions/3.10.6/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/Users/paul/.pyenv/versions/3.10.6/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/Users/paul/.pyenv/versions/3.10.6/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/7z/89c1vd1s6xlcjd9373__jcr40000gn/T/ipykernel_23857/1708662303.py\", line 5, in <module>\n      model.evaluate(X_autre, y_autre)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2200, in evaluate\n      logs = test_function_runner.run_step(\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 4000, in run_step\n      tmp_logs = self._function(dataset_or_iterator)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1972, in test_function\n      return step_function(self, iterator)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1956, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1944, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1853, in test_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1179, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/Users/paul/.pyenv/versions/3.10.6/envs/wagon-give-me-a-sign/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 708, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_test_function_20002]"
     ]
    }
   ],
   "source": [
    "X_autre = df_test.drop(columns=['target'])\n",
    "y_autre = df_test['target']\n",
    "\n",
    "\n",
    "model.evaluate(X_autre, y_autre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not balanced\n",
      "[389 301 200]\n",
      "(1200, 61)\n"
     ]
    }
   ],
   "source": [
    "from load_from_bq import load_from_bq\n",
    "from data_proc import preproc\n",
    "\n",
    "df = load_from_bq()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not balanced\n",
      "[389 301 200]\n",
      "(1200, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>...</th>\n",
       "      <th>z_17</th>\n",
       "      <th>x_18</th>\n",
       "      <th>y_18</th>\n",
       "      <th>z_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>y_19</th>\n",
       "      <th>z_19</th>\n",
       "      <th>x_20</th>\n",
       "      <th>y_20</th>\n",
       "      <th>z_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.042898</td>\n",
       "      <td>-0.029042</td>\n",
       "      <td>-0.022728</td>\n",
       "      <td>0.082919</td>\n",
       "      <td>-0.099549</td>\n",
       "      <td>-0.030895</td>\n",
       "      <td>0.104474</td>\n",
       "      <td>-0.167504</td>\n",
       "      <td>-0.036971</td>\n",
       "      <td>0.107749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015610</td>\n",
       "      <td>-0.013992</td>\n",
       "      <td>-0.216523</td>\n",
       "      <td>-0.029793</td>\n",
       "      <td>-0.007387</td>\n",
       "      <td>-0.161956</td>\n",
       "      <td>-0.019320</td>\n",
       "      <td>-0.017528</td>\n",
       "      <td>-0.151642</td>\n",
       "      <td>-0.008038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.039047</td>\n",
       "      <td>-0.036933</td>\n",
       "      <td>-0.011414</td>\n",
       "      <td>0.068237</td>\n",
       "      <td>-0.109745</td>\n",
       "      <td>-0.014147</td>\n",
       "      <td>0.084549</td>\n",
       "      <td>-0.178962</td>\n",
       "      <td>-0.017134</td>\n",
       "      <td>0.076609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013834</td>\n",
       "      <td>-0.032987</td>\n",
       "      <td>-0.235866</td>\n",
       "      <td>-0.024015</td>\n",
       "      <td>-0.021585</td>\n",
       "      <td>-0.185040</td>\n",
       "      <td>-0.013501</td>\n",
       "      <td>-0.021213</td>\n",
       "      <td>-0.159538</td>\n",
       "      <td>-0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.040251</td>\n",
       "      <td>-0.039287</td>\n",
       "      <td>-0.011242</td>\n",
       "      <td>0.069786</td>\n",
       "      <td>-0.110896</td>\n",
       "      <td>-0.014000</td>\n",
       "      <td>0.086180</td>\n",
       "      <td>-0.179591</td>\n",
       "      <td>-0.017391</td>\n",
       "      <td>0.077457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012279</td>\n",
       "      <td>-0.031406</td>\n",
       "      <td>-0.244421</td>\n",
       "      <td>-0.022634</td>\n",
       "      <td>-0.020061</td>\n",
       "      <td>-0.194669</td>\n",
       "      <td>-0.012388</td>\n",
       "      <td>-0.019291</td>\n",
       "      <td>-0.167679</td>\n",
       "      <td>-0.001657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.032569</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>-0.003696</td>\n",
       "      <td>0.068817</td>\n",
       "      <td>-0.004343</td>\n",
       "      <td>-0.005051</td>\n",
       "      <td>0.093937</td>\n",
       "      <td>-0.025705</td>\n",
       "      <td>-0.008445</td>\n",
       "      <td>0.113761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014285</td>\n",
       "      <td>0.062636</td>\n",
       "      <td>-0.097593</td>\n",
       "      <td>-0.026137</td>\n",
       "      <td>0.048615</td>\n",
       "      <td>-0.065057</td>\n",
       "      <td>-0.020421</td>\n",
       "      <td>0.035163</td>\n",
       "      <td>-0.074106</td>\n",
       "      <td>-0.013037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.040200</td>\n",
       "      <td>-0.009149</td>\n",
       "      <td>-0.013948</td>\n",
       "      <td>0.077157</td>\n",
       "      <td>-0.071257</td>\n",
       "      <td>-0.015537</td>\n",
       "      <td>0.093177</td>\n",
       "      <td>-0.137815</td>\n",
       "      <td>-0.016252</td>\n",
       "      <td>0.095015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012004</td>\n",
       "      <td>-0.002261</td>\n",
       "      <td>-0.235486</td>\n",
       "      <td>-0.026377</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>-0.180850</td>\n",
       "      <td>-0.017632</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>-0.150750</td>\n",
       "      <td>-0.006808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>0.029195</td>\n",
       "      <td>-0.016635</td>\n",
       "      <td>-0.015373</td>\n",
       "      <td>0.050096</td>\n",
       "      <td>-0.067095</td>\n",
       "      <td>-0.022519</td>\n",
       "      <td>0.051992</td>\n",
       "      <td>-0.115718</td>\n",
       "      <td>-0.028059</td>\n",
       "      <td>0.031841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027150</td>\n",
       "      <td>-0.039759</td>\n",
       "      <td>-0.173599</td>\n",
       "      <td>-0.039065</td>\n",
       "      <td>-0.042025</td>\n",
       "      <td>-0.211872</td>\n",
       "      <td>-0.046274</td>\n",
       "      <td>-0.043191</td>\n",
       "      <td>-0.246892</td>\n",
       "      <td>-0.050782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>0.029558</td>\n",
       "      <td>-0.022090</td>\n",
       "      <td>-0.015085</td>\n",
       "      <td>0.050419</td>\n",
       "      <td>-0.074117</td>\n",
       "      <td>-0.021154</td>\n",
       "      <td>0.050614</td>\n",
       "      <td>-0.124967</td>\n",
       "      <td>-0.026062</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021219</td>\n",
       "      <td>-0.027074</td>\n",
       "      <td>-0.194075</td>\n",
       "      <td>-0.030775</td>\n",
       "      <td>-0.026621</td>\n",
       "      <td>-0.231186</td>\n",
       "      <td>-0.036006</td>\n",
       "      <td>-0.026238</td>\n",
       "      <td>-0.266824</td>\n",
       "      <td>-0.039445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>-0.024813</td>\n",
       "      <td>-0.018772</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>-0.066365</td>\n",
       "      <td>-0.030849</td>\n",
       "      <td>-0.003253</td>\n",
       "      <td>-0.100299</td>\n",
       "      <td>-0.020189</td>\n",
       "      <td>-0.008094</td>\n",
       "      <td>-0.123571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049120</td>\n",
       "      <td>-0.100396</td>\n",
       "      <td>0.027819</td>\n",
       "      <td>-0.066554</td>\n",
       "      <td>-0.129722</td>\n",
       "      <td>0.055318</td>\n",
       "      <td>-0.071779</td>\n",
       "      <td>-0.150102</td>\n",
       "      <td>0.078985</td>\n",
       "      <td>-0.073411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>0.027287</td>\n",
       "      <td>-0.009614</td>\n",
       "      <td>-0.012094</td>\n",
       "      <td>0.050694</td>\n",
       "      <td>-0.052471</td>\n",
       "      <td>-0.017446</td>\n",
       "      <td>0.055791</td>\n",
       "      <td>-0.095099</td>\n",
       "      <td>-0.021654</td>\n",
       "      <td>0.037982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024528</td>\n",
       "      <td>-0.014150</td>\n",
       "      <td>-0.171592</td>\n",
       "      <td>-0.033959</td>\n",
       "      <td>-0.010971</td>\n",
       "      <td>-0.206458</td>\n",
       "      <td>-0.039750</td>\n",
       "      <td>-0.007590</td>\n",
       "      <td>-0.238021</td>\n",
       "      <td>-0.043537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>0.039109</td>\n",
       "      <td>-0.022004</td>\n",
       "      <td>-0.015758</td>\n",
       "      <td>0.068443</td>\n",
       "      <td>-0.085744</td>\n",
       "      <td>-0.020164</td>\n",
       "      <td>0.082695</td>\n",
       "      <td>-0.148912</td>\n",
       "      <td>-0.024257</td>\n",
       "      <td>0.075771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017651</td>\n",
       "      <td>-0.004088</td>\n",
       "      <td>-0.250332</td>\n",
       "      <td>-0.029747</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>-0.295338</td>\n",
       "      <td>-0.036415</td>\n",
       "      <td>0.022310</td>\n",
       "      <td>-0.332824</td>\n",
       "      <td>-0.040572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x_1       y_1       z_1       x_2       y_2       z_2       x_3  \\\n",
       "169   0.042898 -0.029042 -0.022728  0.082919 -0.099549 -0.030895  0.104474   \n",
       "97    0.039047 -0.036933 -0.011414  0.068237 -0.109745 -0.014147  0.084549   \n",
       "31    0.040251 -0.039287 -0.011242  0.069786 -0.110896 -0.014000  0.086180   \n",
       "12    0.032569  0.017575 -0.003696  0.068817 -0.004343 -0.005051  0.093937   \n",
       "35    0.040200 -0.009149 -0.013948  0.077157 -0.071257 -0.015537  0.093177   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1106  0.029195 -0.016635 -0.015373  0.050096 -0.067095 -0.022519  0.051992   \n",
       "1014  0.029558 -0.022090 -0.015085  0.050419 -0.074117 -0.021154  0.050614   \n",
       "1092 -0.024813 -0.018772  0.001381 -0.066365 -0.030849 -0.003253 -0.100299   \n",
       "1179  0.027287 -0.009614 -0.012094  0.050694 -0.052471 -0.017446  0.055791   \n",
       "1102  0.039109 -0.022004 -0.015758  0.068443 -0.085744 -0.020164  0.082695   \n",
       "\n",
       "           y_3       z_3       x_4  ...      z_17      x_18      y_18  \\\n",
       "169  -0.167504 -0.036971  0.107749  ... -0.015610 -0.013992 -0.216523   \n",
       "97   -0.178962 -0.017134  0.076609  ... -0.013834 -0.032987 -0.235866   \n",
       "31   -0.179591 -0.017391  0.077457  ... -0.012279 -0.031406 -0.244421   \n",
       "12   -0.025705 -0.008445  0.113761  ... -0.014285  0.062636 -0.097593   \n",
       "35   -0.137815 -0.016252  0.095015  ... -0.012004 -0.002261 -0.235486   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1106 -0.115718 -0.028059  0.031841  ... -0.027150 -0.039759 -0.173599   \n",
       "1014 -0.124967 -0.026062  0.028531  ... -0.021219 -0.027074 -0.194075   \n",
       "1092 -0.020189 -0.008094 -0.123571  ... -0.049120 -0.100396  0.027819   \n",
       "1179 -0.095099 -0.021654  0.037982  ... -0.024528 -0.014150 -0.171592   \n",
       "1102 -0.148912 -0.024257  0.075771  ... -0.017651 -0.004088 -0.250332   \n",
       "\n",
       "          z_18      x_19      y_19      z_19      x_20      y_20      z_20  \n",
       "169  -0.029793 -0.007387 -0.161956 -0.019320 -0.017528 -0.151642 -0.008038  \n",
       "97   -0.024015 -0.021585 -0.185040 -0.013501 -0.021213 -0.159538 -0.002831  \n",
       "31   -0.022634 -0.020061 -0.194669 -0.012388 -0.019291 -0.167679 -0.001657  \n",
       "12   -0.026137  0.048615 -0.065057 -0.020421  0.035163 -0.074106 -0.013037  \n",
       "35   -0.026377  0.004294 -0.180850 -0.017632  0.000837 -0.150750 -0.006808  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1106 -0.039065 -0.042025 -0.211872 -0.046274 -0.043191 -0.246892 -0.050782  \n",
       "1014 -0.030775 -0.026621 -0.231186 -0.036006 -0.026238 -0.266824 -0.039445  \n",
       "1092 -0.066554 -0.129722  0.055318 -0.071779 -0.150102  0.078985 -0.073411  \n",
       "1179 -0.033959 -0.010971 -0.206458 -0.039750 -0.007590 -0.238021 -0.043537  \n",
       "1102 -0.029747  0.007598 -0.295338 -0.036415  0.022310 -0.332824 -0.040572  \n",
       "\n",
       "[840 rows x 60 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "169   a\n",
       "97    a\n",
       "31    a\n",
       "12    a\n",
       "35    a\n",
       "...  ..\n",
       "1106  b\n",
       "1014  b\n",
       "1092  b\n",
       "1179  b\n",
       "1102  b\n",
       "\n",
       "[840 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7379 - accuracy: 0.0000e+00 - val_loss: 1.6163 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6534 - accuracy: 0.4211 - val_loss: 1.5125 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5267 - accuracy: 0.8947 - val_loss: 1.3956 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4101 - accuracy: 1.0000 - val_loss: 1.2470 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2544 - accuracy: 1.0000 - val_loss: 1.0564 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1007 - accuracy: 1.0000 - val_loss: 0.8216 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9157 - accuracy: 1.0000 - val_loss: 0.5593 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6425 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3604 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1990 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1309 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 7.3556e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.3447e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.8307e-04 - accuracy: 1.0000 - val_loss: 3.9723e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.7899e-04 - accuracy: 1.0000 - val_loss: 3.0120e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.1353e-04 - accuracy: 1.0000 - val_loss: 2.3289e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.8768e-04 - accuracy: 1.0000 - val_loss: 1.8339e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.0304e-04 - accuracy: 1.0000 - val_loss: 1.4692e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.9295e-04 - accuracy: 1.0000 - val_loss: 1.1967e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.8465e-04 - accuracy: 1.0000 - val_loss: 9.9018e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.3054e-04 - accuracy: 1.0000 - val_loss: 8.3138e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.7536e-04 - accuracy: 1.0000 - val_loss: 7.0742e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.4056e-04 - accuracy: 1.0000 - val_loss: 6.0941e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4599e-04 - accuracy: 1.0000 - val_loss: 5.3126e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.7241e-04 - accuracy: 1.0000 - val_loss: 4.6808e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0080e-04 - accuracy: 1.0000 - val_loss: 4.1669e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1814e-04 - accuracy: 1.0000 - val_loss: 3.7431e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.9568e-05 - accuracy: 1.0000 - val_loss: 3.3934e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2043e-04 - accuracy: 1.0000 - val_loss: 3.1020e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4667e-04 - accuracy: 1.0000 - val_loss: 2.8517e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3289e-04 - accuracy: 1.0000 - val_loss: 2.6438e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.8008e-05 - accuracy: 1.0000 - val_loss: 2.4663e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2529e-04 - accuracy: 1.0000 - val_loss: 2.3140e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.5243e-05 - accuracy: 1.0000 - val_loss: 2.1842e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1624e-04 - accuracy: 1.0000 - val_loss: 2.0649e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3118e-04 - accuracy: 1.0000 - val_loss: 1.9630e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.0293e-05 - accuracy: 1.0000 - val_loss: 1.8729e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5698e-04 - accuracy: 1.0000 - val_loss: 1.7961e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9413e-04 - accuracy: 1.0000 - val_loss: 1.7272e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.8005e-05 - accuracy: 1.0000 - val_loss: 1.6663e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.9254e-05 - accuracy: 1.0000 - val_loss: 1.6080e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.3039e-05 - accuracy: 1.0000 - val_loss: 1.5630e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.4274e-05 - accuracy: 1.0000 - val_loss: 1.5192e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.5017e-05 - accuracy: 1.0000 - val_loss: 1.4795e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1696e-05 - accuracy: 1.0000 - val_loss: 1.4437e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.1395e-05 - accuracy: 1.0000 - val_loss: 1.4159e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.4241e-05 - accuracy: 1.0000 - val_loss: 1.3841e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9882e-05 - accuracy: 1.0000 - val_loss: 1.3616e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.0548e-05 - accuracy: 1.0000 - val_loss: 1.3391e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.3735e-05 - accuracy: 1.0000 - val_loss: 1.3153e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.9436e-05 - accuracy: 1.0000 - val_loss: 1.2928e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5981e-05 - accuracy: 1.0000 - val_loss: 1.2742e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0887e-05 - accuracy: 1.0000 - val_loss: 1.2596e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.0529e-05 - accuracy: 1.0000 - val_loss: 1.2411e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.5456e-05 - accuracy: 1.0000 - val_loss: 1.2305e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.6156e-05 - accuracy: 1.0000 - val_loss: 1.2186e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.4216e-05 - accuracy: 1.0000 - val_loss: 1.2027e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.7508e-05 - accuracy: 1.0000 - val_loss: 1.1908e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.5271e-05 - accuracy: 1.0000 - val_loss: 1.1775e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.0257e-05 - accuracy: 1.0000 - val_loss: 1.1669e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2033e-04 - accuracy: 1.0000 - val_loss: 1.1563e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.7064e-05 - accuracy: 1.0000 - val_loss: 1.1457e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3502e-05 - accuracy: 1.0000 - val_loss: 1.1351e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0246e-05 - accuracy: 1.0000 - val_loss: 1.1285e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0944e-04 - accuracy: 1.0000 - val_loss: 1.1206e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9989e-05 - accuracy: 1.0000 - val_loss: 1.1113e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.8780e-05 - accuracy: 1.0000 - val_loss: 1.1007e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3966e-05 - accuracy: 1.0000 - val_loss: 1.0980e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.9846e-05 - accuracy: 1.0000 - val_loss: 1.0914e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.3038e-05 - accuracy: 1.0000 - val_loss: 1.0821e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.7323e-05 - accuracy: 1.0000 - val_loss: 1.0769e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.3650e-05 - accuracy: 1.0000 - val_loss: 1.0702e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.6425e-05 - accuracy: 1.0000 - val_loss: 1.0596e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.2989e-05 - accuracy: 1.0000 - val_loss: 1.0477e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6420e-04 - accuracy: 1.0000 - val_loss: 1.0305e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.8381e-05 - accuracy: 1.0000 - val_loss: 1.0159e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.1090e-05 - accuracy: 1.0000 - val_loss: 1.0027e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6613e-05 - accuracy: 1.0000 - val_loss: 9.8943e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.6225e-05 - accuracy: 1.0000 - val_loss: 9.7619e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1633e-05 - accuracy: 1.0000 - val_loss: 9.6692e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0585e-05 - accuracy: 1.0000 - val_loss: 9.5235e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.0936e-05 - accuracy: 1.0000 - val_loss: 9.4042e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.3463e-05 - accuracy: 1.0000 - val_loss: 9.2718e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.7668e-05 - accuracy: 1.0000 - val_loss: 9.1658e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1444e-05 - accuracy: 1.0000 - val_loss: 9.0731e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8546e-05 - accuracy: 1.0000 - val_loss: 8.9804e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3778e-05 - accuracy: 1.0000 - val_loss: 8.8612e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7661e-05 - accuracy: 1.0000 - val_loss: 8.8082e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4115e-05 - accuracy: 1.0000 - val_loss: 8.7022e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4493e-05 - accuracy: 1.0000 - val_loss: 8.5963e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.6965e-05 - accuracy: 1.0000 - val_loss: 8.4903e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.6587e-05 - accuracy: 1.0000 - val_loss: 8.3844e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d9ddee60>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_test, y_train, y_test = preproc(df, test_size=0.3, random_state=42)\n",
    "                                     \n",
    "display(X_train, y_train)                              \n",
    "                                     \n",
    "                                     \n",
    "le = LabelEncoder()\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "n_features = X_train.shape[1] \n",
    "\n",
    "\n",
    "\n",
    "# Transformer les données pour qu'elles aient la bonne forme pour le LSTM\n",
    "\n",
    "# Reshaping X_train for LSTM\n",
    "n_timesteps = 30\n",
    "n_samples_train = np.floor(X_train.shape[0] / n_timesteps).astype(int)\n",
    "X_train = np.resize(X_train, (n_samples_train*n_timesteps, n_features))\n",
    "X_train_lstm = X_train.reshape(n_samples_train, n_timesteps, n_features)\n",
    "\n",
    "# Reshaping y_train to match X_train\n",
    "y_train = np.resize(y_train, (n_samples_train*n_timesteps,))\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_train_encoded = to_categorical(y_train_encoded, num_classes)\n",
    "y_train_encoded = np.resize(y_train_encoded, (n_samples_train, num_classes))\n",
    "\n",
    "# Do the same for X_test and y_test\n",
    "n_samples_test = np.floor(X_test.shape[0] / n_timesteps).astype(int)\n",
    "X_test = np.resize(X_test, (n_samples_test*n_timesteps, n_features))\n",
    "X_test_lstm = X_test.reshape(n_samples_test, n_timesteps, n_features)\n",
    "\n",
    "y_test = np.resize(y_test, (n_samples_test*n_timesteps,))\n",
    "y_test_encoded = le.transform(y_test)\n",
    "y_test_encoded = to_categorical(y_test_encoded, num_classes)\n",
    "y_test_encoded = np.resize(y_test_encoded, (n_samples_test, num_classes))\n",
    "\n",
    "# Continue with model creation and training...\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(n_timesteps, n_features)))  # première couche LSTM\n",
    "model.add(Dropout(0.2))  # régularisation par dropout\n",
    "model.add(Dense(100, activation='relu'))  # une couche Dense pour le traitement après le LSTM\n",
    "model.add(Dropout(0.2))  # régularisation par dropout\n",
    "model.add(Dense(num_classes, activation='softmax'))  # couche de sortie - 26 pour le nombre de lettres dans l'alphabet\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'], run_eagerly=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_lstm, y_train_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train_lstm, y_train_encoded , validation_split=0.30, callbacks=[early_stopping], epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 4.7684e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.768370445162873e-07, 1.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wagon-give-me-a-sign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
